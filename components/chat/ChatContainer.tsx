import React, { useState, useEffect, useRef } from 'react';
import { ChatContainerProps } from './types';
import MessageBubble from './MessageBubble';
import ChatInput from './ChatInput';
import WelcomeMessage from './WelcomeMessage';
import ThinkingIndicator from './ThinkingIndicator';
import StreamingResponse from './StreamingResponse';
import { generateEmbedding, cosineSimilarity, rerankChunks } from '../../services/embeddingService';
import { searchSimilarChunks } from '../../services/tursoService';
import { streamChat } from '../../services/llmService';
import { getRagSettingsService } from '../../services/ragSettingsService';
import { RagSettingsModal } from '../settings';
import { ChatMessage, RagChunk } from '../../types';

const ChatContainer: React.FC<ChatContainerProps> = ({
  session,
  assistantName,
  systemPrompt,
  assistantId,
  ragChunks,
  onNewMessage,
  hideHeader = false,
  sharedMode = false,
  assistantDescription,
}) => {
  const [input, setInput] = useState('');
  const [streamingResponse, setStreamingResponse] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [statusText, setStatusText] = useState('');
  const [isThinking, setIsThinking] = useState(false);
  const [currentSession, setCurrentSession] = useState(session);
  const [showRagSettings, setShowRagSettings] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    setCurrentSession(session);
  }, [session]);

  useEffect(() => {
    scrollToBottom();
  }, [currentSession.messages, streamingResponse, isThinking]);

  const findRelevantContext = async (message: string): Promise<string> => {
    try {
      console.log(`ğŸ¯ [RAG QUERY] Starting context search for query: "${message}"`);
      setStatusText('ğŸ” ç”ŸæˆæŸ¥è©¢åµŒå…¥...');
      const queryVector = await generateEmbedding(message, 'query');

      // å–å¾— RAG è¨­å®š
      const ragSettings = getRagSettingsService();
      const vectorSearchLimit = ragSettings.getVectorSearchLimit();
      const enableReranking = ragSettings.isRerankingEnabled();
      const rerankLimit = ragSettings.getRerankLimit();
      const minSimilarity = ragSettings.getMinSimilarity();

      console.log(
        `âš™ï¸ [RAG SETTINGS] Vector search: ${vectorSearchLimit}, Rerank: ${enableReranking ? rerankLimit : 'disabled'}, Min similarity: ${minSimilarity}`,
      );

      // å„ªå…ˆä½¿ç”¨ Turso å‘é‡æœå°‹
      setStatusText('ğŸŒ æœå°‹çŸ¥è­˜åº« (Turso)...');
      console.log('ğŸ” [RAG QUERY] Attempting Turso vector search first...');
      const tursoResults = await searchSimilarChunks(assistantId, queryVector, vectorSearchLimit);

      if (tursoResults.length > 0) {
        // ä½¿ç”¨ Turso æœå°‹çµæœ
        setStatusText(`ğŸ” å–å¾— ${tursoResults.length} å€‹å€™é¸æ–‡ä»¶...`);
        console.log(`ğŸ“Š [RAG QUERY] Using TURSO results - Found ${tursoResults.length} chunks`);
        const topChunks = tursoResults.filter(chunk => chunk.similarity > minSimilarity);
        console.log(
          `ğŸ“Š [RAG QUERY] Filtered to ${topChunks.length} chunks with similarity > ${minSimilarity}`,
        );

        let finalChunks = topChunks;

        // å¦‚æœå•Ÿç”¨é‡æ–°æ’åºï¼Œé€²è¡Œ reranking
        if (enableReranking && topChunks.length > 0) {
          setStatusText('ğŸ”„ é‡æ–°æ’åºç›¸é—œå…§å®¹...');
          console.log(`ğŸ”„ [RAG QUERY] Starting rerank with ${topChunks.length} chunks`);
          // Convert SimilarChunk to RagChunk for reranking
          const ragChunks = topChunks.map((chunk, index) => ({
            id: `${chunk.fileName}-${index}`,
            fileName: chunk.fileName,
            content: chunk.content,
            chunkIndex: index,
          }));
          const reRanked = await rerankChunks(message, ragChunks, rerankLimit);
          console.log(`ğŸ”„ [RAG QUERY] Re-ranked to ${reRanked.length} top chunks`);

          // Convert back to format with similarity score
          finalChunks = reRanked.map(chunk => ({
            ...chunk,
            similarity: chunk.relevanceScore || 0,
          }));
        } else {
          // å¦‚æœä¸ä½¿ç”¨ rerankingï¼Œç›´æ¥å–å‰ N å€‹
          finalChunks = topChunks.slice(0, rerankLimit);
          console.log(`ğŸ“Š [RAG QUERY] Reranking disabled, using top ${finalChunks.length} chunks`);
        }

        const contextString = finalChunks
          .map(chunk => `From ${chunk.fileName}:\n${chunk.content}`)
          .join('\n\n---\n\n');

        console.log(`ğŸ“ [RAG QUERY] Final context length: ${contextString.length} characters`);
        return contextString;
      }

      // å¾Œå‚™ï¼šå¦‚æœ Turso æœå°‹å¤±æ•—ï¼Œä½¿ç”¨æœ¬åœ° ragChunks
      setStatusText('ğŸ—„ï¸ æœå°‹æœ¬åœ°çŸ¥è­˜åº«...');
      console.log('âš ï¸ [RAG QUERY] Turso search returned no results, falling back to IndexedDB...');
      if (ragChunks.length > 0) {
        setStatusText(`ğŸ“Š åˆ†æ ${ragChunks.length} å€‹æœ¬åœ°æ–‡ä»¶...`);
        console.log(
          `ğŸ” [RAG QUERY] Using INDEXEDDB fallback - Processing ${ragChunks.length} local chunks`,
        );

        const scoredChunks = (ragChunks as RagChunk[]).map(chunk => ({
          ...chunk,
          similarity: chunk.vector ? cosineSimilarity(queryVector, chunk.vector) : 0,
        }));

        scoredChunks.sort((a, b) => b.similarity - a.similarity);
        const topChunks = scoredChunks.slice(0, vectorSearchLimit);
        const relevantChunks = topChunks.filter(chunk => chunk.similarity > minSimilarity);

        console.log(
          `ğŸ“Š [RAG QUERY] IndexedDB filtered to ${relevantChunks.length} chunks with similarity > ${minSimilarity}`,
        );

        let finalChunks = relevantChunks;

        // å¦‚æœå•Ÿç”¨é‡æ–°æ’åºï¼Œé€²è¡Œ reranking
        if (enableReranking && relevantChunks.length > 0) {
          setStatusText('ğŸ”„ é‡æ–°æ’åºç›¸é—œå…§å®¹...');
          const reRanked = await rerankChunks(
            message,
            relevantChunks.filter(c => c.vector),
            rerankLimit,
          );
          console.log(`ğŸ”„ [RAG QUERY] Re-ranked to ${reRanked.length} top chunks`);

          // Convert reRanked results back to the same format as relevantChunks
          finalChunks = reRanked.map(chunk => ({
            ...chunk,
            similarity: chunk.relevanceScore || 0,
          }));
        } else {
          // å¦‚æœä¸ä½¿ç”¨ rerankingï¼Œç›´æ¥å–å‰ N å€‹
          finalChunks = relevantChunks.slice(0, rerankLimit);
          console.log(`ğŸ“Š [RAG QUERY] Reranking disabled, using top ${finalChunks.length} chunks`);
        }

        const contextString = finalChunks
          .map(chunk => `From ${chunk.fileName}:\n${chunk.content}`)
          .join('\n\n---\n\n');

        console.log(`ğŸ“ [RAG QUERY] Final context length: ${contextString.length} characters`);
        return contextString;
      }

      console.log(
        'âŒ [RAG QUERY] No context found - neither Turso nor IndexedDB had relevant data',
      );
      return '';
    } catch (error) {
      console.error('âŒ [RAG QUERY] Error finding relevant context:', error);
      setStatusText('âŒ æœå°‹çŸ¥è­˜åº«æ™‚ç™¼ç”ŸéŒ¯èª¤');
      return ''; // Return empty context on error
    }
  };

  const handleSend = async () => {
    if (!input.trim() || isLoading) {
      return;
    }
    const userMessage = input.trim();
    setInput('');
    setIsLoading(true);
    setIsThinking(true);
    setStreamingResponse('');

    // ç«‹å³é¡¯ç¤ºç”¨æˆ¶è¨Šæ¯
    const newUserMessage = { role: 'user' as const, content: userMessage };
    const updatedSession = {
      ...currentSession,
      messages: [...currentSession.messages, newUserMessage],
    };
    setCurrentSession(updatedSession);

    try {
      let ragContext = '';
      ragContext = await findRelevantContext(userMessage);

      if (ragContext) {
        setStatusText('ğŸ§  å·²æ“·å–çŸ¥è­˜ã€‚ç”Ÿæˆä¸Šä¸‹æ–‡åŒ–å›ç­”...');
      } else {
        setStatusText('ğŸ¤– ç”Ÿæˆå›ç­”...');
      }

      // Prepare chat history with compression support
      let chatHistory: ChatMessage[];
      let enhancedSystemPrompt = systemPrompt;

      // Step 1: Add RAG context to system prompt first (if available)
      if (ragContext) {
        const ragPreamble = `Use the information from the following context to inform your response to the user's question. Provide a natural, conversational answer as if the information is part of your general knowledge, without mentioning the context or documents directly. If the answer is not found in the provided information, state that you don't have the relevant information to answer the question.\n\n<context>\n${ragContext}\n</context>`;
        enhancedSystemPrompt = `${systemPrompt}\n\n${ragPreamble}`;
      }

      // Step 2: Add compressed conversation context (if available)
      if (currentSession.compactContext) {
        const compactedContextPrompt = `\n\n[PREVIOUS CONVERSATION SUMMARY]\n${currentSession.compactContext.content}\n\nThe above is a summary of our previous conversation. Please refer to this context when responding to continue our conversation naturally.\n\n[CURRENT CONVERSATION]`;

        enhancedSystemPrompt = `${enhancedSystemPrompt}${compactedContextPrompt}`;

        // Use only the preserved recent messages for history
        chatHistory = currentSession.messages;

        console.log('ğŸ“œ [CHAT HISTORY] Using compressed context in system prompt:', {
          compactTokens: currentSession.compactContext.tokenCount,
          compressedRounds: currentSession.compactContext.compressedFromRounds,
          preservedMessages: currentSession.messages.length,
          systemPromptLength: enhancedSystemPrompt.length,
        });
      } else {
        // No compression, use regular message history
        chatHistory = currentSession.messages;
        console.log('ğŸ“œ [CHAT HISTORY] Using regular history:', {
          messageCount: chatHistory.length,
        });
      }

      await streamChat({
        systemPrompt: enhancedSystemPrompt,
        ragContext: '', // Pass empty since we've already integrated RAG into system prompt
        history: chatHistory,
        message: userMessage,
        onChunk: chunk => {
          if (isThinking) {
            setIsThinking(false); // ç¬¬ä¸€å€‹ chunk åˆ°é”æ™‚åœæ­¢ thinking å‹•ç•«
          }
          setStreamingResponse(prev => prev + chunk);
        },
        onComplete: (tokenInfo, fullModelResponse) => {
          setIsLoading(false);
          setIsThinking(false);
          setStatusText('');

          // å‰µå»º AI å›æ‡‰è¨Šæ¯
          const newAiMessage = { role: 'model' as const, content: fullModelResponse };
          const finalSession = {
            ...updatedSession,
            messages: [...updatedSession.messages, newAiMessage],
            tokenCount:
              (updatedSession.tokenCount || 0) +
              tokenInfo.promptTokenCount +
              tokenInfo.candidatesTokenCount,
          };

          setCurrentSession(finalSession);
          setStreamingResponse('');

          // é€šçŸ¥çˆ¶çµ„ä»¶æ›´æ–°
          onNewMessage(finalSession, userMessage, fullModelResponse, tokenInfo);
        },
      });
    } catch (error) {
      console.error('Error during chat stream:', error);
      setIsLoading(false);
      setIsThinking(false);
      setStatusText('');
      setStreamingResponse(
        `æŠ±æ­‰ï¼Œç™¼ç”ŸéŒ¯èª¤ã€‚API è¿”å›ä»¥ä¸‹éŒ¯èª¤ï¼š\n\n${(error as Error).message}\n\nè«‹æª¢æŸ¥æ‚¨çš„ API å¯†é‘°å’Œæ§åˆ¶æª¯ä»¥å–å¾—æ›´å¤šç´°ç¯€ã€‚`,
      );
    }
  };

  return (
    <div className='flex flex-col h-full bg-gray-900'>
      {/* Optional Header */}
      {!hideHeader && (
        <div className='p-4 border-b border-gray-700 flex-shrink-0 bg-gray-800'>
          <div className='flex items-center justify-between'>
            <h2 className='text-xl font-semibold text-white'>{assistantName}</h2>
            <button
              onClick={() => setShowRagSettings(true)}
              className={`flex items-center space-x-2 px-3 py-1.5 rounded-md transition-colors text-sm font-medium ${
                sharedMode
                  ? 'bg-blue-700 hover:bg-blue-600 text-blue-100 hover:text-white'
                  : 'bg-gray-700 hover:bg-gray-600 text-gray-300 hover:text-white'
              }`}
              title={sharedMode ? 'å…¨åŸŸ RAG æœå°‹è¨­å®š' : 'RAG æœå°‹è¨­å®š'}
            >
              <svg className='w-4 h-4' fill='none' stroke='currentColor' viewBox='0 0 24 24'>
                <path
                  strokeLinecap='round'
                  strokeLinejoin='round'
                  strokeWidth={2}
                  d='M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z'
                />
              </svg>
              <span>RAG è¨­å®š</span>
            </button>
          </div>
        </div>
      )}

      {/* Messages Area */}
      <main className='flex-1 overflow-y-auto chat-scroll' role='main' aria-label='èŠå¤©å°è©±'>
        <div className='max-w-4xl mx-auto px-4 py-6'>
          {/* Welcome Message for Empty Chat */}
          {currentSession.messages.length === 0 && !streamingResponse && !isThinking && (
            <WelcomeMessage
              assistantName={assistantName}
              assistantDescription={assistantDescription}
              sharedMode={sharedMode}
            />
          )}

          {/* Message List */}
          <div className='space-y-8'>
            {currentSession.messages.map((msg, index) => (
              <MessageBubble
                key={index}
                message={msg}
                index={index}
                assistantName={assistantName}
              />
            ))}

            {/* Thinking Placeholder */}
            {isThinking && !streamingResponse && <ThinkingIndicator />}

            {/* Streaming Response */}
            {streamingResponse && <StreamingResponse content={streamingResponse} />}
          </div>
          <div ref={messagesEndRef} />
        </div>
      </main>

      {/* Input Area */}
      <ChatInput
        value={input}
        onChange={setInput}
        onSend={handleSend}
        isLoading={isLoading}
        statusText={statusText}
        currentSession={currentSession}
        disabled={false}
      />

      {/* RAG Settings Modal */}
      <RagSettingsModal isOpen={showRagSettings} onClose={() => setShowRagSettings(false)} />
    </div>
  );
};

export default ChatContainer;
